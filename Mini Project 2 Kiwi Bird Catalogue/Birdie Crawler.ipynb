# -*- coding: utf-8 -*-
# Birdieland Crawler

"""## Setup"""
# Scrapping 
from bs4 import BeautifulSoup
import requests

# Data preprocessing
import re
import pandas as pd

"""## Scrap, chirp chirp!"""

name_db = []
status_db = []
maori_name_db = []
image_url_db = []

COUNT = 10

for i in range(COUNT):

    url = f"https://www.nzbirdsonline.org.nz/name-search?title=&field_other_names_value=&field_search_scientific_name_value=&page={i}"

    bird_page = requests.get(url).text
    soup = BeautifulSoup(bird_page, 'lxml')

    print(f"Crawling birds in page {i}...")

    names = soup.find_all("h3", class_="search-result-title")
    status = soup.find_all("p", class_="search-result-status")
    maori_names = soup.find_all('p', class_="search-result-othernames")
    image_urls = soup.find_all("img", class_="search-result-image")

    # textify name, status, maori name
    for j in range(COUNT):
        name = names[j].text
        name_db.append(name)

        stat = status[j].text
        status_db.append(stat)
        
        try: 
            maori_name = maori_names[j].text
            maori_name_db.append(maori_name)
        except:
            maori_name_db.append("no name")

    # extract url from tags
    pattern = "https.*"
    remove = '\"\/\>'

    for url in image_urls:
        url = str(url)
        match = re.findall(pattern, url)
        if (match):
            match = re.sub(remove, "", match[0])
            image_url_db.append(match)

print("Crawling completed, chirp chirp!")

"""# Data Quality check"""

print(len(name_db), len(status_db), len(maori_name_db), len(image_url_db))

for i in range(len(name_db)):
    print(f"{i}: {name_db[i]}, {status_db[i]}, {image_url_db[i]}")

data = {'name': name_db, 'status': status_db, 'maori_name': maori_name_db, 'url': image_url_db}
bird_df = pd.DataFrame(data)
bird_df.head()

features = ['name', 'maori_name', 'url']

for feature in features: 
    print(bird_df[feature].value_counts())

"""## Save to `.json`"""

bird_df.to_json("bird.json", orient="records")
